{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from peft_trainer import ModelType\n",
    "\n",
    "modelType = ModelType.LGAI_EXAONE3_5_8B_INSTRUCT\n",
    "print(modelType.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from peft_trainer import train_sft\n",
    "# 모델 학습\n",
    "model, tokenlizer, output_dir = train_sft(\n",
    "            modelType, use_quantization = True, max_seq_length = 1024,\n",
    "            wandb_project = 'finetuning', wandb_key=\"6d3af81c45ae2105a65a2b8dc7074e35ab8bfb5c\", \n",
    "            lorar = 8, loraa = 16, loradropout = 0.2, targetmodule=LoraTarget.FULL,\n",
    "            epochs= 3, batch_size = 4, gradient_step = 2, learning_rate = 7e-4\n",
    "            )\n",
    "\n",
    "lora_path = output_dir + \"/lora_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
